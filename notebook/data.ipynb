{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    \"\"\"返回文本列表和标签列表.\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    current_text = []\n",
    "    current_label = []\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()  # 删除行首和行尾的空白字符\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        word, label = line.split('\\t')\n",
    "        current_text.append(word)\n",
    "        current_label.append(label)\n",
    "        \n",
    "        # 以句号（。）或分号（；）分割\n",
    "        # if word in ['。', '？']:  \n",
    "        if word == '。':  \n",
    "            texts.append(current_text)\n",
    "            labels.append(current_label)\n",
    "            current_text = []\n",
    "            current_label = []\n",
    "            \n",
    "    # 如果最后一个句子没有以句号或分号结束，也添加到结果中\n",
    "    if current_text:\n",
    "        texts.append(current_text)\n",
    "        labels.append(current_label)\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "def numericalize_labels(labels, label_map):\n",
    "    \"\"\"将标签列表转换为数字列表.\"\"\"\n",
    "    numericalized_labels = []\n",
    "    for label_list in labels:\n",
    "      numericalized_labels.append([label_map[label] for label in label_list])\n",
    "    return numericalized_labels\n",
    "\n",
    "def no_samples(texts, numericalized_labels, max_len=510):\n",
    "    \"\"\"创建样本，每个样本都是以句号分割的一句话及其标签.\"\"\"\n",
    "    samples = []\n",
    "    \n",
    "    for i in range(len(texts)):\n",
    "        # 确保每个句子（即以句号分隔的文本）的长度不超过max_len\n",
    "        if len(\"\".join(texts[i])) <= max_len:\n",
    "          samples.append((\"\".join(texts[i]), numericalized_labels[i]))\n",
    "        else:\n",
    "          # 如果句子长度超过max_len，则进行截断\n",
    "          truncated_text = \"\".join(texts[i])[:max_len]\n",
    "          \n",
    "          # 找到截断后的文本中最后一个字符在原始标签列表中的索引。\n",
    "          truncated_len = 0\n",
    "          for j, word in enumerate(texts[i]):\n",
    "            truncated_len += len(word)\n",
    "            if truncated_len > max_len:\n",
    "                break\n",
    "\n",
    "          # 截断标签列表\n",
    "          truncated_labels = numericalized_labels[i][:j]\n",
    "\n",
    "          samples.append((truncated_text, truncated_labels))\n",
    "    return samples\n",
    "\n",
    "def create_samples(texts, numericalized_labels, max_len=512, min_overlap_rate=0.0, max_overlap_rate=0.5):\n",
    "    \"\"\"创建带有随机重叠的样本，样本长度和重叠率随机.\"\"\"\n",
    "    samples = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(texts):\n",
    "        sample_text = []\n",
    "        sample_label = []\n",
    "        \n",
    "        current_len = 0\n",
    "        start_index = i\n",
    "        \n",
    "        # 随机生成当前样本的最大长度\n",
    "        # current_max_len = random.randint(32, max_len)\n",
    "        current_max_len = max_len\n",
    "\n",
    "        while current_len < current_max_len and i < len(texts):\n",
    "            \n",
    "            sentence_len = len(texts[i])\n",
    "            \n",
    "            if current_len + sentence_len <= current_max_len:\n",
    "                sample_text.extend(texts[i])\n",
    "                sample_label.extend(numericalized_labels[i])\n",
    "                current_len += sentence_len\n",
    "                i += 1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        if len(sample_text) > 0:\n",
    "            samples.append((\"\".join(sample_text),sample_label))\n",
    "        \n",
    "        # 随机重叠率\n",
    "        overlap_rate = random.uniform(min_overlap_rate, max_overlap_rate)\n",
    "        # 计算重叠的起始位置\n",
    "        overlap = int(len(texts[start_index:i]) * overlap_rate)\n",
    "        i = max(start_index + (len(texts[start_index:i]) - overlap), start_index+1)\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../data/EvaHan2025_traingdata/trainset_C.txt'\n",
    "texts, labels = load_data(filepath)\n",
    "\n",
    "# label_map = {\n",
    "#     \"O\": 0,\n",
    "#     \"B-NR\": 1,\n",
    "#     \"M-NR\": 2,\n",
    "#     \"E-NR\": 3,\n",
    "#     \"S-NR\": 4,\n",
    "#     \"B-NS\": 5,\n",
    "#     \"M-NS\": 6,\n",
    "#     \"E-NS\": 7,\n",
    "#     \"S-NS\": 8,\n",
    "#     \"B-NB\": 9,\n",
    "#     \"M-NB\": 10,\n",
    "#     \"E-NB\": 11,\n",
    "#     \"S-NB\": 12,\n",
    "#     \"B-NO\": 13,\n",
    "#     \"M-NO\": 14,\n",
    "#     \"E-NO\": 15,\n",
    "#     \"S-NO\": 16,\n",
    "#     \"B-NG\": 17,\n",
    "#     \"M-NG\": 18,\n",
    "#     \"E-NG\": 19,\n",
    "#     \"S-NG\": 20,\n",
    "#     \"B-T\": 21,\n",
    "#     \"M-T\": 22,\n",
    "#     \"E-T\": 23,\n",
    "#     \"S-T\": 24,\n",
    "# }\n",
    "\n",
    "# label_map = {\n",
    "#     \"O\": 0,\n",
    "#     \"B-NR\": 1,\n",
    "#     \"M-NR\": 2,\n",
    "#     \"E-NR\": 3,\n",
    "#     \"S-NR\": 4,\n",
    "#     \"B-NS\": 5,\n",
    "#     \"M-NS\": 6,\n",
    "#     \"E-NS\": 7,\n",
    "#     \"S-NS\": 8,\n",
    "#     \"B-T\": 9,\n",
    "#     \"M-T\": 10,\n",
    "#     \"E-T\": 11,\n",
    "#     \"S-T\": 12,\n",
    "# }\n",
    "\n",
    "label_map = {\n",
    "    \"O\": 0,\n",
    "    \"B-ZD\": 1,\n",
    "    \"M-ZD\": 2,\n",
    "    \"E-ZD\": 3,\n",
    "    \"S-ZD\": 4,\n",
    "    \"B-ZZ\": 5,\n",
    "    \"M-ZZ\": 6,\n",
    "    \"E-ZZ\": 7,\n",
    "    \"S-ZZ\": 8,\n",
    "    \"B-ZF\": 9,\n",
    "    \"M-ZF\": 10,\n",
    "    \"E-ZF\": 11,\n",
    "    \"S-ZF\": 12,\n",
    "    \"B-ZP\": 13,\n",
    "    \"M-ZP\": 14,\n",
    "    \"E-ZP\": 15,\n",
    "    \"S-ZP\": 16,\n",
    "    \"B-ZS\": 17,\n",
    "    \"M-ZS\": 18,\n",
    "    \"E-ZS\": 19,\n",
    "    \"S-ZS\": 20,\n",
    "    \"B-ZA\": 21,\n",
    "    \"M-ZA\": 22,\n",
    "    \"E-ZA\": 23,\n",
    "    \"S-ZA\": 24,\n",
    "}\n",
    "\n",
    "numericalized_labels = numericalize_labels(labels, label_map)\n",
    "# samples = create_samples(texts, numericalized_labels)\n",
    "samples = no_samples(texts, numericalized_labels)\n",
    "\n",
    "# 计算分割点\n",
    "split_point = int(len(samples) * 1)\n",
    "random.shuffle(samples)\n",
    "train_samples = samples[:split_point]\n",
    "test_samples = samples[split_point:]\n",
    "\n",
    "text_output_path = '../data/text_C.txt'  # 训练文本文件的路径\n",
    "label_output_path = '../data/label_C.txt'  # 训练标签文件的路径\n",
    "text_test_output_path = '../data/text_C_test.txt' # 测试文本文件的路径\n",
    "label_test_output_path = '../data/label_C_test.txt' # 测试标签文件的路径\n",
    "\n",
    "with open(text_test_output_path, 'w', encoding='utf-8') as text_test_file, \\\n",
    "    open(label_test_output_path, 'w', encoding='utf-8') as label_test_file:\n",
    "    for text, label in test_samples:\n",
    "        text_test_file.write(text + '\\n')\n",
    "        label_test_file.write(str(label) + '\\n')\n",
    "\n",
    "with open(text_output_path, 'w', encoding='utf-8') as text_file, \\\n",
    "        open(label_output_path, 'w', encoding='utf-8') as label_file:\n",
    "    for text, label in train_samples:\n",
    "        text_file.write(text + '\\n')  # 将文本写入文件，每个样本一行\n",
    "        label_file.write(str(label) + '\\n')  # 将数字标签列表转换为字符串并写入文件，每个样本一行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentences(filepath):\n",
    "    \"\"\"读取文件并按句号分割文本，返回句子列表.\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()  # 读取整个文件内容\n",
    "\n",
    "    # 按句号分割文本\n",
    "    sentences = text.split('。')\n",
    "    \n",
    "    # 去除空字符串，并处理最后一个句子\n",
    "    result_sentences = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        sentence = sentence.strip()\n",
    "        if sentence:  # 确保句子不为空\n",
    "            if i == len(sentences) - 1 and not sentence.endswith('。'):\n",
    "                # 如果是最后一个句子且没有句号，保留原样\n",
    "                result_sentences.append(sentence)\n",
    "            else:\n",
    "                # 其他句子末尾添加句号\n",
    "                result_sentences.append(sentence + '。')\n",
    "    \n",
    "    return result_sentences\n",
    "\n",
    "def save_sentences(sentences, output_path):\n",
    "    \"\"\"将句子列表保存到文件，每个句子一行.\"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for sentence in sentences:\n",
    "            f.write(sentence + '\\n')\n",
    "\n",
    "# 输入文件路径\n",
    "input_file_path = '../data/TestSet/raw/testset_B.txt'  # 输入文件的路径\n",
    "output_file_path = '../data/TestSet/test_B.txt'  # 输出文件的路径\n",
    "\n",
    "# 加载句子\n",
    "sentences = load_sentences(input_file_path)\n",
    "\n",
    "# 保存句子到输出文件\n",
    "save_sentences(sentences, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
