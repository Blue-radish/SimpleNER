{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaNer.ipynb  EvaNer.py  data.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-crf in /home/radish/anaconda3/envs/eva/lib/python3.10/site-packages (0.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import AutoModel\n",
    "from transformers import AdamW\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from torchcrf import CRF  # 引入 CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    transformers.set_seed(seed)\n",
    "\n",
    "same_seeds(7890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at ../model/GujiRoBERTa_jian_fan and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 768])\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../model/GujiRoBERTa_jian_fan\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "model = AutoModel.from_pretrained(model_path, local_files_only=True)\n",
    "\n",
    "\n",
    "# 示例文本\n",
    "text = \"主唱太拼命了\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "print(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3405,\n",
       " ['我', '命', '旨', '酒', '，', '以', '歌', '以', '謡', '。'],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TextLabelDataset(Dataset):\n",
    "    def __init__(self, text_file, label_file, max_length=510):\n",
    "        \"\"\"\n",
    "            text_file: 文本文件的路径.\n",
    "            label_file: 标签文件的路径.\n",
    "            tokenizer_name: 使用的 tokenizer 名称，默认为 'bert-base-chinese'.\n",
    "            max_length: 最大序列长度，默认 510.\n",
    "        \"\"\"\n",
    "        self.text_file = text_file\n",
    "        self.label_file = label_file\n",
    "        self.max_length = max_length\n",
    "        self.texts, self.labels = self._load_data()\n",
    "        \n",
    "        self.dataset = self._filter_long_sentences() # 过滤掉过长的句子\n",
    "\n",
    "    def _filter_long_sentences(self):\n",
    "        \"\"\"过滤掉过长的句子\"\"\"\n",
    "        filtered_texts = []\n",
    "        filtered_labels = []\n",
    "        for text, label in zip(self.texts, self.labels):\n",
    "            if len(text) <= self.max_length:\n",
    "                filtered_texts.append(text)\n",
    "                filtered_labels.append(label)\n",
    "\n",
    "        return list(zip(filtered_texts,filtered_labels))\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"\n",
    "        加载文本和标签数据。返回包含文本列表和标签列表的元组.\n",
    "        \"\"\"\n",
    "        texts = []\n",
    "        labels = []\n",
    "        with open(self.text_file, 'r', encoding='utf-8') as f_text, \\\n",
    "                open(self.label_file, 'r', encoding='utf-8') as f_label:\n",
    "            for text, label in zip(f_text, f_label):\n",
    "                texts.append(list(text.strip()))\n",
    "                labels.append(eval(label.strip()))  # 使用 eval 将字符串转换为 list\n",
    "        return texts, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens, labels = self.dataset[idx]\n",
    "        return tokens, labels\n",
    "\n",
    "\n",
    "text_file = '../data/text_B.txt'  # 文本文件的路径\n",
    "label_file = '../data/label_B.txt'  # 标签文件的路径\n",
    "dataset = TextLabelDataset(text_file, label_file)\n",
    "tokens, labels = dataset[5]\n",
    "\n",
    "len(dataset), tokens, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': tensor([[ 101, 3501, 2300, 1251, 4761,  780, 2336, 8024, 2603, 2617, 4158,  679,\n",
      "         3791, 8024, 6298, 5885, 1814, 4761, 5238, 4374, 4509, 5389, 8024, 3462,\n",
      "         6843, 4352,  511,  102,    0,    0],\n",
      "        [ 101, 1350, 5800, 2134, 2200, 5635, 3745, 1814, 8024, 4352, 1401, 1315,\n",
      "         1343, 1071, 3431, 3451, 8024, 2876, 6342, 5445, 1139,  722, 8024,  718,\n",
      "         6210, 3176, 6662,  979,  511,  102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}, tensor([[13,  1,  2,  3,  0,  5,  7,  0,  0,  0,  0,  0,  0,  0,  0,  5,  7,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0, 13, 13, 13],\n",
      "        [13,  0,  1,  3,  0,  0,  5,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 13]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(data):\n",
    "    tokens = [i[0] for i in data]\n",
    "    labels = [i[1] for i in data]\n",
    "\n",
    "    inputs = tokenizer.batch_encode_plus(tokens,\n",
    "                                         truncation=True,\n",
    "                                         padding=True,\n",
    "                                         return_tensors='pt',\n",
    "                                         is_split_into_words=True) \n",
    "\n",
    "    lens = inputs['input_ids'].shape[1]\n",
    "    # print(lens)\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        labels[i] = [13] + labels[i]\n",
    "        labels[i] += [13] * lens\n",
    "        labels[i] = labels[i][:lens]\n",
    "\n",
    "    return inputs.to(device), torch.LongTensor(labels).to(device)  # 将输入和标签都移动到设备上\n",
    "    # return inputs, torch.LongTensor(labels)\n",
    "\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                     batch_size=2,\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True)\n",
    "\n",
    "i = 0\n",
    "for data in loader:\n",
    "    i += 1\n",
    "    if i == 4:\n",
    "        print(data)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at ../model/GujiRoBERTa_jian_fan and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11269.7856\n"
     ]
    }
   ],
   "source": [
    "#加载预训练模型\n",
    "model_path = \"../model/GujiRoBERTa_jian_fan\"\n",
    "pretrained = AutoModel.from_pretrained(model_path, local_files_only=True).to(device)\n",
    "# pretrained = AutoModel.from_pretrained(model_path, local_files_only=True)\n",
    "\n",
    "\n",
    "#统计参数量\n",
    "print(sum(i.numel() for i in pretrained.parameters()) / 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义下游模型\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tuneing = False\n",
    "        self.pretrained = None\n",
    "\n",
    "        self.rnn = torch.nn.LSTM(768, 768, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(768, 14)\n",
    "        self.crf = CRF(14, batch_first=True)\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        if self.tuneing:\n",
    "            out = self.pretrained(**inputs).last_hidden_state\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                out = pretrained(**inputs).last_hidden_state\n",
    "\n",
    "        out, _ = self.rnn(out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        if labels is not None:\n",
    "            # 如果提供了 labels，则计算 CRF loss\n",
    "            mask = inputs['attention_mask'].bool()\n",
    "            loss = -self.crf(out, labels, mask=mask, reduction='mean')\n",
    "            return loss\n",
    "        else:\n",
    "            # 否则，使用 CRF 进行解码\n",
    "            mask = inputs['attention_mask'].bool()\n",
    "            prediction = self.crf.decode(out, mask=mask)\n",
    "            return prediction\n",
    "\n",
    "    def fine_tuneing(self, tuneing):\n",
    "        self.tuneing = tuneing\n",
    "        if tuneing:\n",
    "            for i in pretrained.parameters():\n",
    "                i.requires_grad = True\n",
    "\n",
    "            pretrained.train()\n",
    "            self.pretrained = pretrained\n",
    "        else:\n",
    "            for i in pretrained.parameters():\n",
    "                i.requires_grad_(False)\n",
    "\n",
    "            pretrained.eval()\n",
    "            self.pretrained = None\n",
    "\n",
    "\n",
    "model = Model().to(device)\n",
    "# model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #对计算结果和label变形,并且移除pad\n",
    "# def reshape_and_remove_pad(outs, labels, attention_mask):\n",
    "#     #变形,便于计算loss\n",
    "#     outs = outs.reshape(-1, 14)\n",
    "#     labels = labels.reshape(-1)\n",
    "\n",
    "#     #忽略对pad的计算结果\n",
    "#     select = attention_mask.reshape(-1) == 1\n",
    "#     outs = outs[select]\n",
    "#     labels = labels[select]\n",
    "\n",
    "#     return outs, labels\n",
    "\n",
    "\n",
    "# reshape_and_remove_pad(torch.randn(2, 3, 14), torch.ones(2, 3),\n",
    "#                        torch.ones(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_and_total_count(labels, outs, attention_mask):\n",
    "    # 将预测结果和标签都转换为一维列表\n",
    "    active_outs = [item for sublist in outs for item in sublist]  # outs 本身已经是 list of lists，直接展平\n",
    "    active_labels = []\n",
    "    \n",
    "    # 遍历每个样本的标签和对应的 attention_mask\n",
    "    for label_seq, mask_seq in zip(labels, attention_mask):\n",
    "        for label, mask in zip(label_seq, mask_seq):\n",
    "            if mask:  # 只保留 attention_mask 中为 True 的部分\n",
    "                active_labels.append(label.item())\n",
    "\n",
    "    # 确保 active_outs 和 active_labels 都是 list\n",
    "    active_outs = [int(item) for item in active_outs]\n",
    "    active_labels = [int(item) for item in active_labels]\n",
    "\n",
    "    # 转换成 tensor\n",
    "    active_outs = torch.tensor(active_outs).to(device)\n",
    "    active_labels = torch.tensor(active_labels).to(device)\n",
    "\n",
    "    correct = (active_outs == active_labels).sum().item()\n",
    "    total = len(active_labels)\n",
    "\n",
    "    # 计算除了0以外元素的正确率\n",
    "    select = (active_labels != 0)\n",
    "    active_outs = active_outs[select]\n",
    "    active_labels = active_labels[select]\n",
    "    correct_content = (active_outs == active_labels).sum().item()\n",
    "    total_content = len(active_labels)\n",
    "\n",
    "    return correct, total, correct_content, total_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    lr = 2e-5 if model.tuneing else 5e-4\n",
    "    # lr = 1e-5 if model.tuneing else 1e-4\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        progress_bar = tqdm(loader, desc=\"Training\", unit=\"batch\")\n",
    "\n",
    "        for step, (inputs, labels) in enumerate(progress_bar):\n",
    "\n",
    "            # 将输入移动到设备\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 梯度下降\n",
    "            loss = model(inputs, labels) # 直接用 model 计算 loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                with torch.no_grad():\n",
    "                  outs = model(inputs) # 得到预测结果\n",
    "                  counts = get_correct_and_total_count(labels, outs, inputs['attention_mask'])\n",
    "                  accuracy = counts[0] / counts[1] if counts[1] > 0 else 0\n",
    "                  accuracy_content = counts[2] / counts[3] if counts[3] > 0 else 0\n",
    "\n",
    "                progress_bar.set_postfix({\n",
    "                    \"loss\": f\"{loss.item():.4f}\",\n",
    "                    \"accuracy\": f\"{accuracy:.4f}\",\n",
    "                    # \"accuracy_content\": f\"{accuracy_content:.4f}\",\n",
    "                    \"accuracy_content\": f\"{accuracy_content}\",\n",
    "                })\n",
    "        \n",
    "        torch.save(model, '../model/NER_crf_lstm_B.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473.5726\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████| 1702/1702 [02:17<00:00, 12.36batch/s, loss=0.2599, accuracy=1.0000, accuracy_content=1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████| 1702/1702 [02:18<00:00, 12.30batch/s, loss=1.7593, accuracy=1.0000, accuracy_content=1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█| 1702/1702 [02:30<00:00, 11.29batch/s, loss=7.3795, accuracy=0.9016, accuracy_content=0.863636363636363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████| 1702/1702 [02:39<00:00, 10.69batch/s, loss=0.4687, accuracy=1.0000, accuracy_content=1.0]\n"
     ]
    }
   ],
   "source": [
    "model.fine_tuneing(False)\n",
    "print(sum(p.numel() for p in model.parameters()) / 10000)\n",
    "train(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11743.3582\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████| 1702/1702 [09:49<00:00,  2.89batch/s, loss=0.7117, accuracy=1.0000, accuracy_content=1.0]\n"
     ]
    }
   ],
   "source": [
    "model.fine_tuneing(True)\n",
    "print(sum(p.numel() for p in model.parameters()) / 10000)\n",
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]故意合則胡越爲昆弟，由余、越人蒙是矣；不合，則骨肉出逐不收，朱、象、管、蔡是矣。[SEP]\n",
      "Label: [CLS]25··········由1余3·越1人2蒙3··············朱4·象4·管4·蔡4···[SEP]25\n",
      "Out: [CLS]25··········由1余3·越1人2蒙3··············朱4·象4·管4·蔡4···[SEP]25\n",
      "==========================\n",
      "[CLS]攻齊所以大破者，以其伐楚而肥韓、魏也。[SEP]\n",
      "Label: [CLS]25·齊20·········楚20··韓20·魏20··[SEP]25\n",
      "Out: [CLS]25·齊20·········楚20··韓20·魏20··[SEP]25\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "text_file = '../data/text_C_test.txt'\n",
    "label_file = '../data/label_C_test.txt'\n",
    "\n",
    "#测试\n",
    "def predict():\n",
    "    model_load = torch.load('../model/NER_crf_C.model', weights_only=False)\n",
    "    model_load.eval()\n",
    "\n",
    "    loader_test = torch.utils.data.DataLoader(dataset=TextLabelDataset(text_file, label_file),\n",
    "                                              batch_size=2,\n",
    "                                              collate_fn=collate_fn,\n",
    "                                              shuffle=True,\n",
    "                                              drop_last=True)\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(loader_test):\n",
    "        break\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outs = model_load(inputs) # outs 直接是解码后的结果，是一个 list of lists\n",
    "\n",
    "    for i in range(2):\n",
    "        # 移除 pad\n",
    "        select = inputs['attention_mask'][i] == 1\n",
    "        input_id = inputs['input_ids'][i, select]\n",
    "        out = outs[i]  # 直接使用 outs[i] 获取当前样本的预测标签序列\n",
    "        label = labels[i, select]\n",
    "\n",
    "        # 输出原句子\n",
    "        print(tokenizer.decode(input_id).replace(' ', ''))\n",
    "\n",
    "        # 输出 tag\n",
    "        # 标签\n",
    "        s = ''\n",
    "        for j in range(len(label)):\n",
    "            if label[j] == 0:\n",
    "                s += '·'\n",
    "                continue\n",
    "            s += tokenizer.decode(input_id[j])\n",
    "            s += str(label[j].item())\n",
    "        print(\"Label:\", s)\n",
    "\n",
    "        # 预测\n",
    "        s = ''\n",
    "        for j in range(len(out)):\n",
    "            if out[j] == 0:\n",
    "                s += '·'\n",
    "                continue\n",
    "            s += tokenizer.decode(input_id[j])\n",
    "            s += str(out[j])\n",
    "        print(\"Out:\", s)\n",
    "\n",
    "        print('==========================')\n",
    "\n",
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 33, 5, 6)\n",
      "(57, 57, 11, 11)\n",
      "(42, 42, 7, 7)\n",
      "(64, 64, 19, 19)\n",
      "(35, 35, 9, 9)\n",
      "0.9956709956709957 0.9807692307692307\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "def test():\n",
    "    model_load = torch.load('../model/NER_crf_C.model', weights_only=False)\n",
    "    model_load.eval()\n",
    "\n",
    "    loader_test = torch.utils.data.DataLoader(dataset=TextLabelDataset(text_file, label_file),\n",
    "                                              batch_size=2,\n",
    "                                              collate_fn=collate_fn,\n",
    "                                              shuffle=True,\n",
    "                                              drop_last=True)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    correct_content = 0\n",
    "    total_content = 0\n",
    "\n",
    "    for step, (inputs, labels) in enumerate(loader_test):\n",
    "        if step == 5:\n",
    "            break\n",
    "        # print(step)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outs = model_load(inputs) # outs 直接是解码后的结果，是一个 list of lists\n",
    "\n",
    "        counts = get_correct_and_total_count(labels, outs, inputs['attention_mask'])\n",
    "        print(counts)\n",
    "        correct += counts[0]\n",
    "        total += counts[1]\n",
    "        correct_content += counts[2]\n",
    "        total_content += counts[3]\n",
    "\n",
    "    print(correct / total, correct_content / total_content)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
