{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaNer.ipynb  EvaNer.py  data.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-crf in /home/radish/anaconda3/envs/eva/lib/python3.10/site-packages (0.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radish/anaconda3/envs/eva/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import AutoModel\n",
    "from transformers import AdamW\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from torchcrf import CRF  # 引入 CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    transformers.set_seed(seed)\n",
    "\n",
    "same_seeds(7890)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at ../model/GujiRoBERTa_jian_fan and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 768])\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../model/GujiRoBERTa_jian_fan\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "model = AutoModel.from_pretrained(model_path, local_files_only=True)\n",
    "\n",
    "\n",
    "# 示例文本\n",
    "text = \"主唱太拼命了\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "print(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1491,\n",
       " ['今',\n",
       "  '楚',\n",
       "  '地',\n",
       "  '方',\n",
       "  '五',\n",
       "  '千',\n",
       "  '里',\n",
       "  '，',\n",
       "  '持',\n",
       "  '戟',\n",
       "  '百',\n",
       "  '萬',\n",
       "  '，',\n",
       "  '此',\n",
       "  '霸',\n",
       "  '王',\n",
       "  '之',\n",
       "  '資',\n",
       "  '也',\n",
       "  '。',\n",
       "  '以',\n",
       "  '楚',\n",
       "  '之',\n",
       "  '彊',\n",
       "  '，',\n",
       "  '天',\n",
       "  '下',\n",
       "  '弗',\n",
       "  '能',\n",
       "  '當',\n",
       "  '。',\n",
       "  '白',\n",
       "  '起',\n",
       "  '，',\n",
       "  '小',\n",
       "  '豎',\n",
       "  '子',\n",
       "  '耳',\n",
       "  '，',\n",
       "  '率',\n",
       "  '數',\n",
       "  '萬',\n",
       "  '之',\n",
       "  '衆',\n",
       "  '，',\n",
       "  '興',\n",
       "  '師',\n",
       "  '以',\n",
       "  '與',\n",
       "  '楚',\n",
       "  '戰',\n",
       "  '，',\n",
       "  '一',\n",
       "  '戰',\n",
       "  '而',\n",
       "  '舉',\n",
       "  '鄢',\n",
       "  '郢',\n",
       "  '，',\n",
       "  '再',\n",
       "  '戰',\n",
       "  '而',\n",
       "  '燒',\n",
       "  '夷',\n",
       "  '陵',\n",
       "  '，',\n",
       "  '三',\n",
       "  '戰',\n",
       "  '而',\n",
       "  '辱',\n",
       "  '王',\n",
       "  '之',\n",
       "  '先',\n",
       "  '人',\n",
       "  '。',\n",
       "  '此',\n",
       "  '百',\n",
       "  '世',\n",
       "  '之',\n",
       "  '怨',\n",
       "  '而',\n",
       "  '趙',\n",
       "  '之',\n",
       "  '所',\n",
       "  '羞',\n",
       "  '，',\n",
       "  '而',\n",
       "  '王',\n",
       "  '弗',\n",
       "  '知',\n",
       "  '惡',\n",
       "  '焉',\n",
       "  '。',\n",
       "  '合',\n",
       "  '從',\n",
       "  '者',\n",
       "  '爲',\n",
       "  '楚',\n",
       "  '，',\n",
       "  '非',\n",
       "  '爲',\n",
       "  '趙',\n",
       "  '也',\n",
       "  '。'],\n",
       " [24,\n",
       "  20,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  20,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  20,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  8,\n",
       "  8,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  20,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  20,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  20,\n",
       "  0,\n",
       "  0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TextLabelDataset(Dataset):\n",
    "    def __init__(self, text_file, label_file, max_length=128):\n",
    "        \"\"\"\n",
    "            text_file: 文本文件的路径.\n",
    "            label_file: 标签文件的路径.\n",
    "            tokenizer_name: 使用的 tokenizer 名称，默认为 'bert-base-chinese'.\n",
    "            max_length: 最大序列长度，默认 128.\n",
    "        \"\"\"\n",
    "        self.text_file = text_file\n",
    "        self.label_file = label_file\n",
    "        self.max_length = max_length\n",
    "        self.texts, self.labels = self._load_data()\n",
    "        \n",
    "        self.dataset = self._filter_long_sentences() # 过滤掉过长的句子\n",
    "\n",
    "    def _filter_long_sentences(self):\n",
    "        \"\"\"过滤掉过长的句子.\"\"\"\n",
    "        filtered_texts = []\n",
    "        filtered_labels = []\n",
    "        for text, label in zip(self.texts, self.labels):\n",
    "            if len(text) <= self.max_length:\n",
    "                filtered_texts.append(text)\n",
    "                filtered_labels.append(label)\n",
    "\n",
    "        return list(zip(filtered_texts,filtered_labels))\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"\n",
    "        加载文本和标签数据。返回包含文本列表和标签列表的元组.\n",
    "        \"\"\"\n",
    "        texts = []\n",
    "        labels = []\n",
    "        with open(self.text_file, 'r', encoding='utf-8') as f_text, \\\n",
    "                open(self.label_file, 'r', encoding='utf-8') as f_label:\n",
    "            for text, label in zip(f_text, f_label):\n",
    "                texts.append(list(text.strip()))\n",
    "                labels.append(eval(label.strip()))  # 使用 eval 将字符串转换为 list\n",
    "        return texts, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens, labels = self.dataset[idx]\n",
    "        return tokens, labels\n",
    "\n",
    "\n",
    "text_file = '../data/text_A.txt'  # 文本文件的路径\n",
    "label_file = '../data/label_A.txt'  # 标签文件的路径\n",
    "dataset = TextLabelDataset(text_file, label_file)\n",
    "tokens, labels = dataset[5]\n",
    "\n",
    "len(dataset), tokens, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': tensor([[  101,  4264,  1724,  7386,  8024,  1724,   758,  2541,   722,  8024,\n",
      "           679,  5543,  1139,   511,  1071,  2200,  6725,  6635,  2886,  1139,\n",
      "         23186,  1293,  5632,  3011,  2782,  8024,  4912,  6725,  2198,  3669,\n",
      "          6635,  2886,   511,  2886,  6725,  3134,  8024,  1293,  1724,  1282,\n",
      "          5857,   782,  7360,  3636,  2128,  1409,   511,  3636,  2128,  1409,\n",
      "          6243,  3288,  8038,   519,  1184,  4912,  2347,  2869,   677,  7955,\n",
      "          8024,   677,  7955,  3696,   679,  3556,  4264,  4912,  5445,  3645,\n",
      "          6635,   511,  6635,  1293,  1353,  6208,   511,  7478,  4674,  3669,\n",
      "           722,  8024,  2607,  4264,   748,   511,   520,   718,  2925,  6266,\n",
      "          5445,  4674, 23621,  3669,   722,  8024,  6909,  1071,  2207,  5442,\n",
      "           753,  4636,  1724,  1282,   782,  3645,  6635,   511,  1184,  2527,\n",
      "          3170,  7674,  5996,  1724,  1282,   758,  5857,   782,   511,  6635,\n",
      "           782,  1920,  7448,   511,   102],\n",
      "        [  101,  6296,  2533,  3557,  2200,  6725,  7674,  5645,  4242,  4719,\n",
      "           768,   722,  1765,  1756,  8024,  1938,  4368,  4912,  4374,  8024,\n",
      "          4912,  4374,  2553,  6304,  6210,  5628,  8024,  5628,   718,  2533,\n",
      "          3300,   809,  1841,   511,   520,  1922,  2094,  3288,  8038,   519,\n",
      "          3557,  2200,  6725,  4981,  1737,   889,  3645,   710,  8024,   710,\n",
      "           679,  2556,   809,  2346,   722,  4900,  5445,  1003,  7269,  5442,\n",
      "           722,  2692,  8024,  7544,  6639,   678,  3291,  2719,   722,  8013,\n",
      "           520,  5769, 21591,  4761,  1922,  2094,   679,  2556,  8024,   718,\n",
      "          6876,  4900,  6210,  3557,  3176,  3309,  3288,  8038,   519,  4912,\n",
      "           722,  6878,  2200,  6725,  1377,  6333,  3918,  4760,  8024,  4266,\n",
      "          3678,  2134,  3184,  4639,  4264,  2781,  3766,   511,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0]], device='cuda:0')}, tensor([[25,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 13, 15,  1,\n",
      "          3,  0,  0,  0,  0,  0,  0,  0, 20,  0,  0,  0,  1,  3,  0,  4,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  1,  2,  3,  0,  1,  2,  3,  0,  0,  0,  0,\n",
      "          0, 20,  0,  0,  5,  7,  0,  5,  7,  0,  0,  0,  0, 20,  0,  0, 20,  0,\n",
      "         20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 20,  0,\n",
      "         24, 24,  0,  0,  0,  0,  0,  0,  0,  0,  0, 20,  0,  0,  0,  0, 25],\n",
      "        [25,  0,  0,  1,  2,  3,  0,  0, 20,  5,  7,  0,  0,  0,  0,  0,  0,  1,\n",
      "          3,  0,  1,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  1,  2,  3,  0,  0,  0,  0,  4,  0,  4,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
      "          3,  0,  1,  3,  0,  0,  0,  0,  0,  0,  0,  1,  2,  3,  0,  0,  0, 20,\n",
      "          0,  0, 13, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25]],\n",
      "       device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(data):\n",
    "    tokens = [i[0] for i in data]\n",
    "    labels = [i[1] for i in data]\n",
    "\n",
    "    inputs = tokenizer.batch_encode_plus(tokens,\n",
    "                                         truncation=True,\n",
    "                                         padding=True,\n",
    "                                         return_tensors='pt',\n",
    "                                         is_split_into_words=True) \n",
    "\n",
    "    lens = inputs['input_ids'].shape[1]\n",
    "    # print(lens)\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        labels[i] = [25] + labels[i]\n",
    "        labels[i] += [25] * lens\n",
    "        labels[i] = labels[i][:lens]\n",
    "\n",
    "    return inputs.to(device), torch.LongTensor(labels).to(device)  # 将输入和标签都移动到设备上\n",
    "    # return inputs, torch.LongTensor(labels)\n",
    "\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                     batch_size=2,\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True)\n",
    "\n",
    "i = 0\n",
    "for data in loader:\n",
    "    i += 1\n",
    "    if i == 4:\n",
    "        print(data)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at ../model/GujiRoBERTa_jian_fan and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11269.7856\n"
     ]
    }
   ],
   "source": [
    "#加载预训练模型\n",
    "model_path = \"../model/GujiRoBERTa_jian_fan\"\n",
    "pretrained = AutoModel.from_pretrained(model_path, local_files_only=True).to(device)\n",
    "# pretrained = AutoModel.from_pretrained(model_path, local_files_only=True)\n",
    "\n",
    "\n",
    "#统计参数量\n",
    "print(sum(i.numel() for i in pretrained.parameters()) / 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义下游模型\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tuneing = False\n",
    "        self.pretrained = None\n",
    "\n",
    "        # self.rnn = torch.nn.GRU(768, 768, batch_first=True)\n",
    "        self.fc1 = torch.nn.Linear(768, 512)\n",
    "        self.fc2 = torch.nn.Linear(512, 26)\n",
    "        self.crf = CRF(26, batch_first=True)  # 添加 CRF 层\n",
    "\n",
    "    def forward(self, inputs, labels=None): # 修改 forward 函数\n",
    "        if self.tuneing:\n",
    "            out = self.pretrained(**inputs).last_hidden_state\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                out = pretrained(**inputs).last_hidden_state\n",
    "\n",
    "        # out, _ = self.rnn(out)\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        if labels is not None:\n",
    "            # 如果提供了 labels，则计算 CRF loss\n",
    "            mask = inputs['attention_mask'].bool()\n",
    "            loss = -self.crf(out, labels, mask=mask, reduction='mean')\n",
    "            return loss\n",
    "        else:\n",
    "            # 否则，使用 CRF 进行解码\n",
    "            mask = inputs['attention_mask'].bool()\n",
    "            prediction = self.crf.decode(out, mask=mask)\n",
    "            return prediction\n",
    "\n",
    "    def fine_tuneing(self, tuneing):\n",
    "        self.tuneing = tuneing\n",
    "        if tuneing:\n",
    "            for i in pretrained.parameters():\n",
    "                i.requires_grad = True\n",
    "\n",
    "            pretrained.train()\n",
    "            self.pretrained = pretrained\n",
    "        else:\n",
    "            for i in pretrained.parameters():\n",
    "                i.requires_grad_(False)\n",
    "\n",
    "            pretrained.eval()\n",
    "            self.pretrained = None\n",
    "\n",
    "\n",
    "model = Model().to(device)\n",
    "# model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #对计算结果和label变形,并且移除pad\n",
    "# def reshape_and_remove_pad(outs, labels, attention_mask):\n",
    "#     #变形,便于计算loss\n",
    "#     outs = outs.reshape(-1, 26)\n",
    "#     labels = labels.reshape(-1)\n",
    "\n",
    "#     #忽略对pad的计算结果\n",
    "#     select = attention_mask.reshape(-1) == 1\n",
    "#     outs = outs[select]\n",
    "#     labels = labels[select]\n",
    "\n",
    "#     return outs, labels\n",
    "\n",
    "\n",
    "# reshape_and_remove_pad(torch.randn(2, 3, 26), torch.ones(2, 3),\n",
    "#                        torch.ones(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_and_total_count(labels, outs, attention_mask):\n",
    "    # 将预测结果和标签都转换为一维列表\n",
    "    active_outs = [item for sublist in outs for item in sublist]  # outs 本身已经是 list of lists，直接展平\n",
    "    active_labels = []\n",
    "    \n",
    "    # 遍历每个样本的标签和对应的 attention_mask\n",
    "    for label_seq, mask_seq in zip(labels, attention_mask):\n",
    "        for label, mask in zip(label_seq, mask_seq):\n",
    "            if mask:  # 只保留 attention_mask 中为 True 的部分\n",
    "                active_labels.append(label.item())\n",
    "\n",
    "    # 确保 active_outs 和 active_labels 都是 list\n",
    "    active_outs = [int(item) for item in active_outs]\n",
    "    active_labels = [int(item) for item in active_labels]\n",
    "\n",
    "    # 转换成 tensor\n",
    "    active_outs = torch.tensor(active_outs).to(device)\n",
    "    active_labels = torch.tensor(active_labels).to(device)\n",
    "\n",
    "    correct = (active_outs == active_labels).sum().item()\n",
    "    total = len(active_labels)\n",
    "\n",
    "    # 计算除了0以外元素的正确率\n",
    "    select = (active_labels != 0)\n",
    "    active_outs = active_outs[select]\n",
    "    active_labels = active_labels[select]\n",
    "    correct_content = (active_outs == active_labels).sum().item()\n",
    "    total_content = len(active_labels)\n",
    "\n",
    "    return correct, total, correct_content, total_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #训练\n",
    "# def train(epochs):\n",
    "#     # lr = 2e-5 if model.tuneing else 5e-4\n",
    "#     lr = 1e-5 if model.tuneing else 1e-4    \n",
    "#     optimizer = AdamW(model.parameters(), lr=lr)\n",
    "#     # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     model.train()\n",
    "#     for epoch in range(epochs):\n",
    "#         for step, (inputs, labels) in enumerate(loader):\n",
    "#             outs = model(inputs)\n",
    "            \n",
    "#             #对outs和label变形,并且移除pad\n",
    "#             outs, labels = reshape_and_remove_pad(outs, labels,\n",
    "#                                                 inputs['attention_mask'])\n",
    "\n",
    "#             #梯度下降\n",
    "#             loss = criterion(outs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             if step % 50 == 0:\n",
    "#                 counts = get_correct_and_total_count(labels, outs)\n",
    "\n",
    "#                 accuracy = counts[0] / counts[1]\n",
    "#                 accuracy_content = counts[2] / counts[3]\n",
    "\n",
    "#                 print(epoch, step, loss.item(), accuracy, accuracy_content)\n",
    "\n",
    "#         torch.save(model, '../model/NER_ZH.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    lr = 2e-5 if model.tuneing else 5e-4\n",
    "    # lr = 1e-5 if model.tuneing else 1e-4\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # # 计算每个类别的样本数量\n",
    "    # label_counts = [0] * 26  # 有26个类别\n",
    "    # for _, labels in dataset:\n",
    "    #     for label in labels:\n",
    "    #         if label != 25:\n",
    "    #           label_counts[label] += 1\n",
    "\n",
    "    # # 计算权重，做倒数\n",
    "    # weights = [1.0 / count if count > 0 else 0 for count in label_counts]\n",
    "    # weights = torch.tensor(weights).to(device)\n",
    "\n",
    "    # criterion = torch.nn.CrossEntropyLoss(weight=weights, ignore_index=25) \n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        progress_bar = tqdm(loader, desc=\"Training\", unit=\"batch\")\n",
    "\n",
    "        for step, (inputs, labels) in enumerate(progress_bar):\n",
    "\n",
    "            # 将输入移动到设备\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 梯度下降\n",
    "            loss = model(inputs, labels) # 直接用 model 计算 loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                with torch.no_grad():\n",
    "                  outs = model(inputs) # 得到预测结果\n",
    "                  counts = get_correct_and_total_count(labels, outs, inputs['attention_mask'])\n",
    "                  accuracy = counts[0] / counts[1] if counts[1] > 0 else 0\n",
    "                  accuracy_content = counts[2] / counts[3] if counts[3] > 0 else 0\n",
    "\n",
    "                progress_bar.set_postfix({\n",
    "                    \"loss\": f\"{loss.item():.4f}\",\n",
    "                    \"accuracy\": f\"{accuracy:.4f}\",\n",
    "                    # \"accuracy_content\": f\"{accuracy_content:.4f}\",\n",
    "                    \"accuracy_content\": f\"{accuracy_content}\",\n",
    "                })\n",
    "        \n",
    "        torch.save(model, '../model/NER_ZH.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radish/anaconda3/envs/eva/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.7794\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 745/745 [01:10<00:00, 10.63batch/s, loss=17.0045, accuracy=0.9167, accuracy_content=0.8]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 745/745 [01:07<00:00, 11.02batch/s, loss=3.0452, accuracy=0.9957, accuracy_content=0.9705882352941176] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 745/745 [01:10<00:00, 10.62batch/s, loss=5.9724, accuracy=0.9877, accuracy_content=0.9583333333333334] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 745/745 [01:11<00:00, 10.38batch/s, loss=2.5367, accuracy=0.9837, accuracy_content=0.9333333333333333] \n"
     ]
    }
   ],
   "source": [
    "model.fine_tuneing(False)\n",
    "print(sum(p.numel() for p in model.parameters()) / 10000)\n",
    "train(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11310.565\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 745/745 [01:29<00:00,  8.32batch/s, loss=1.6133, accuracy=0.9955, accuracy_content=0.9861111111111112] \n"
     ]
    }
   ],
   "source": [
    "model.fine_tuneing(True)\n",
    "print(sum(p.numel() for p in model.parameters()) / 10000)\n",
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_255687/980635995.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_load = torch.load('../model/NER_ZH.model')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]法不當砭灸，砭灸至氣逐。」問臣意：「師慶安受之？聞於齊諸侯不？」對曰：「不知慶所師受。慶家富，善爲醫，不肯爲人治病，當以此故不聞。慶又告臣意曰：『慎毋令我子孫知若學我方也。』」問臣意：「師慶何見於意而愛意，欲悉教意方？」對曰：「臣意不聞師慶爲方善也。[SEP]\n",
      "Label: [CLS]25···············意4···慶4······齊20···········慶4····慶4·····················慶4···意4····················意4···慶4···意4··意4····意4········意4···慶4·····[SEP]25\n",
      "Out: [CLS]25···············意4···慶4······齊20···········慶4····慶4·····················慶4···意4····················意4···慶4···意4··意4····意4········意4···慶4·····[SEP]25\n",
      "==========================\n",
      "[CLS]今青臣等又面諛以重陛下過，非忠臣也。」始皇下其議丞相。丞相謬其説，絀其辭，乃上書曰：「古者天下散亂，莫能相一，是以諸侯並作，語皆道古以害今，飾虚言以亂實，人善其所私學，以非上所建立。[SEP]\n",
      "Label: [CLS]25今24青4·················始1皇3···丞13相15·丞13相15······························································[SEP]25\n",
      "Out: [CLS]25今24青1臣3················始1皇3···丞13相15·丞13相15··············古21者23··············································[SEP]25\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "text_file = '../data/text_A_test.txt'\n",
    "label_file = '../data/label_A_test.txt'\n",
    "\n",
    "#测试\n",
    "def predict():\n",
    "    model_load = torch.load('../model/NER_ZH.model')\n",
    "    model_load.eval()\n",
    "\n",
    "    loader_test = torch.utils.data.DataLoader(dataset=TextLabelDataset(text_file, label_file),\n",
    "                                              batch_size=2,\n",
    "                                              collate_fn=collate_fn,\n",
    "                                              shuffle=True,\n",
    "                                              drop_last=True)\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(loader_test):\n",
    "        break\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outs = model_load(inputs) # outs 直接是解码后的结果，是一个 list of lists\n",
    "\n",
    "    for i in range(2):\n",
    "        # 移除 pad\n",
    "        select = inputs['attention_mask'][i] == 1\n",
    "        input_id = inputs['input_ids'][i, select]\n",
    "        out = outs[i]  # 直接使用 outs[i] 获取当前样本的预测标签序列\n",
    "        label = labels[i, select]\n",
    "\n",
    "        # 输出原句子\n",
    "        print(tokenizer.decode(input_id).replace(' ', ''))\n",
    "\n",
    "        # 输出 tag\n",
    "        # 标签\n",
    "        s = ''\n",
    "        for j in range(len(label)):\n",
    "            if label[j] == 0:\n",
    "                s += '·'\n",
    "                continue\n",
    "            s += tokenizer.decode(input_id[j])\n",
    "            s += str(label[j].item())\n",
    "        print(\"Label:\", s)\n",
    "\n",
    "        # 预测\n",
    "        s = ''\n",
    "        for j in range(len(out)):\n",
    "            if out[j] == 0:\n",
    "                s += '·'\n",
    "                continue\n",
    "            s += tokenizer.decode(input_id[j])\n",
    "            s += str(out[j])\n",
    "        print(\"Out:\", s)\n",
    "\n",
    "        print('==========================')\n",
    "\n",
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_255687/3722035986.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_load = torch.load('../model/NER_ZH.model')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 258, 50, 59)\n",
      "(241, 244, 56, 56)\n",
      "(230, 231, 30, 31)\n",
      "(223, 227, 74, 75)\n",
      "(233, 236, 46, 48)\n",
      "0.9832775919732442 0.9516728624535316\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "def test():\n",
    "    model_load = torch.load('../model/NER_ZH.model')\n",
    "    model_load.eval()\n",
    "\n",
    "    loader_test = torch.utils.data.DataLoader(dataset=TextLabelDataset(text_file, label_file),\n",
    "                                              batch_size=2,\n",
    "                                              collate_fn=collate_fn,\n",
    "                                              shuffle=True,\n",
    "                                              drop_last=True)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    correct_content = 0\n",
    "    total_content = 0\n",
    "\n",
    "    for step, (inputs, labels) in enumerate(loader_test):\n",
    "        if step == 5:\n",
    "            break\n",
    "        # print(step)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outs = model_load(inputs) # outs 直接是解码后的结果，是一个 list of lists\n",
    "\n",
    "        counts = get_correct_and_total_count(labels, outs, inputs['attention_mask'])\n",
    "        print(counts)\n",
    "        correct += counts[0]\n",
    "        total += counts[1]\n",
    "        correct_content += counts[2]\n",
    "        total_content += counts[3]\n",
    "\n",
    "    print(correct / total, correct_content / total_content)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eva",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
